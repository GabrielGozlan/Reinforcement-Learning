{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8989c07b-8e50-4ce3-9e9b-7588ac8000a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Agent_DQN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 168/990 [02:54<15:11,  1.11s/it]"
     ]
    }
   ],
   "source": [
    "u=0\n",
    "episodes = 990\n",
    "lossLimTrain = -1\n",
    "batch_size = 64\n",
    "refreshQ = 1\n",
    "refreshQTarget = 50000\n",
    "reset_init = 1\n",
    "replay_buffer_SIZE = 10000\n",
    "epsilonDecreasing = 100\n",
    "reward_factor = 4\n",
    "PredList_batch = 10000\n",
    "PredFirstUpdate = 1000\n",
    "\n",
    "NewPosReward=np.array([(-1.1,u*7,0),(-1,u*6,0),(-0.9,u*5,0),(-0.8,u*4,0),(-0.7,u*3,0),(-0.6,u*2,0),(-0.4,u*2,0),(-0.3,u*3,0),(-0.2,u*4,0),(-0.1,u*5,0),(0,u*6,0),(0.1,u*7,0),(0.2,u*8,0),(0.3,u*9,0),(0.4,u*10,0),(0.5,20*u,0)])\n",
    "NewVelReward=np.array([(0.001,1),(-0.001,1)])\n",
    "No = np.array([None])\n",
    "DQN = DQNAgent(\"id0\",epsilonMax = 1, PredFirstUpdate = PredFirstUpdate, PredList_batch = PredList_batch, reward_factor = reward_factor, epsilonMin = 0.05, batch_size = batch_size, contReward = False, arrayNewPosReward = No, arrayNewVelReward = No, replay_buffer_SIZE = replay_buffer_SIZE)\n",
    "episodesHistory, rewardHistory, lossHistory, gradHistory, cumulativeHistory, lossRNDHistory, Q_Trained = DQN.train(episodes,lossLim=lossLimTrain, limitStep = 200,buffer_fill = True, refreshQTarget = refreshQTarget, refreshQ = refreshQ, debug_mode = False, recap_mode=False, reset_init = reset_init, uniqueReward = False, excludePassivity = False, epsilonDecreasing =epsilonDecreasing)\n",
    "\n",
    "plot_all_results(episodesHistory, rewardHistory, lossHistory, gradHistory, cumulativeHistory, lossRNDHistory, episodes, u, batch_size, reward_factor, refreshQTarget, reset_init, replay_buffer_SIZE, epsilonDecreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f20965-73c5-4268-8a38-b3ef1a4b61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Multi_Layer_Perceptron(input_dim = 2,intern_dim = 64, output_dim = 3, depth = 2, isBiased = False)\n",
    "Q.load_state_dict(Q_Trained)\n",
    "DQN_Test = DQNAgent(\"idTest\", env=gym.make('MountainCar-v0', render_mode='human'))\n",
    "DQN_Test.Q = Q\n",
    "DQN_Test.play(seed = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
